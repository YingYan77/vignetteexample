---
title: "Wording Experiment Example"
author: "Ying Yan (21-603-188)"
date: "2025-03-26"
output:
  pdf_document:
    citation_package: biblatex
    latex_engine: lualatex
biblio-style: apa
header-includes: \usepackage{hyperref}
bibliography: wordexperiment.bib
biblatexoptions: [backend=biber]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data and Code
The original survey data is taken from the supplementary material of @Albertson_Jessee_2023. The pseudo-
survey dataset is generated by ChatGPT by describing exactly the same setup and sample size as
the paper. The exact wording of this data generation prompt is shown in the Appendix. The data
generation code generated by ChatGPT and the code for this replication and comparison are available
at [Github](https://github.com/YingYan77/vignetteexample/tree/main).

```{r data-preparation, include=FALSE}
# loading data
library(rio)
library(mice)
library(stargazer)

DAT <- import("supplementary material-replicate codes/raw_data.dta")
pseudo.dat <- read.csv("data_recialresentment.csv")

# creating indicator for welfare/aid to poor 
# question wording
DAT$welfare_word <- NA
DAT$welfare_word[!is.na(DAT$Q32)] <- 1
DAT$welfare_word[!is.na(DAT$Q33)] <- 0

pseudo.dat$welfare_word <- NA
pseudo.dat$welfare_word[!is.na(pseudo.dat$Q32)] <- 1
pseudo.dat$welfare_word[!is.na(pseudo.dat$Q33)] <- 0

# creating welfare/assistance to the poor spending 
# response, combining across question wordings
DAT$spend <- ifelse(DAT$welfare_word==1, c(1, -1, 0)[DAT$Q32],
                    ifelse(DAT$welfare_word==0, c(1, -1, 0)[DAT$Q33], NA))

pseudo.dat$spend <- ifelse(pseudo.dat$welfare_word==1, c(1, -1, 0)[pseudo.dat$Q32],
                           ifelse(pseudo.dat$welfare_word==0, c(1, -1, 0)[pseudo.dat$Q33], NA))

# dropping the 1 observation with everything missing
DAT <- subset(DAT, !is.na(spend))

# dummy for asking RR battery post-experiment
DAT$rr_post <- 1 - DAT$race_first

# racial resentment scale
# first recoding each item 
DAT$rr1.raw <- (5 - DAT$Q22) / 4
DAT$rr2.raw <- (DAT$Q23 - 1) / 4
DAT$rr3.raw <- (DAT$Q24 - 1) / 4
DAT$rr4.raw <- (5 - DAT$Q25) / 4

# imputing missing RR items 
RRmice <- mice(cbind(DAT$rr1.raw, DAT$rr2.raw, DAT$rr3.raw, DAT$rr4.raw),
               seed=12345, method="pmm", maxit=100, m=10, print=FALSE)
RRimputed <- complete(RRmice)

DAT$rr1 <- RRimputed[,1]
DAT$rr2 <- RRimputed[,2]
DAT$rr3 <- RRimputed[,3]
DAT$rr4 <- RRimputed[,4]

pseudo.dat$rr1 <- (5 - pseudo.dat$Q22) / 4
pseudo.dat$rr2 <- (pseudo.dat$Q23 - 1) / 4
pseudo.dat$rr3 <- (pseudo.dat$Q24 - 1) / 4
pseudo.dat$rr4 <- (5 - pseudo.dat$Q25) / 4

# RR scale
DAT$rr_scale <- (DAT$rr1 + DAT$rr2 + DAT$rr3 + DAT$rr4) / 4
pseudo.dat$rr_scale <- (pseudo.dat$rr1 + pseudo.dat$rr2 + pseudo.dat$rr3 + pseudo.dat$rr4) / 4

```

# The Descriptive Demographics

# The Regression Results
## Table 1: Effect of Question Wording on Spending Veiws (Ignoring Question Order)
The result from the original survey data is:

```{r reg1, echo=FALSE, results='asis'}
# Model 1
reg11 <- lm(spend ~ welfare_word, data=DAT)
# summary(reg11)

# Model 2
reg12 <- lm(spend ~ welfare_word + rr_scale, data=DAT)
# summary(reg12)

# Model 3
reg13 <- lm(spend ~ welfare_word*rr_scale, data=DAT)
# summary(reg13)

stargazer(reg11, reg12, reg13,
          title="Orignal Survey Results as Table 1",
          digits=2, intercept.bottom=FALSE, header=FALSE)

```

The result of data generated by ChatGPT is follows:
```{r reg1-pseudo, echo=FALSE, results='asis'}
# Model 1
reg11.pseudo <- lm(spend ~ welfare_word, data=pseudo.dat)
# summary(reg11)

# Model 2
reg12.pseudo <- lm(spend ~ welfare_word + rr_scale, data=pseudo.dat)
# summary(reg12)

# Model 3
reg13.pseudo <- lm(spend ~ welfare_word*rr_scale, data=pseudo.dat)
# summary(reg13)

# outputting to formatted txt table
stargazer(reg11.pseudo, reg12.pseudo, reg13.pseudo, 
          title="Pseudo Survey Results as Table 1",
          digits=2, intercept.bottom=FALSE, header=FALSE)

```

## Table 2: Regression Predicting Spending Preferences on Welfare/Assistance to the Poor
The regression result from original dataset: 
```{r reg2, echo=FALSE, results='asis'}
# Model 1
reg21 <- lm(spend ~ welfare_word*rr_post,
           data=DAT)
# summary(reg21)

# Model 2
reg22 <- lm(spend ~ welfare_word*rr_post*rr_scale,
            data=DAT)
# summary(reg22)

# outputting to nice txt table
# NOTE: R's ordering of coefficients in Model 2
#       differs slightly from that in the text
stargazer(reg21, reg22,
          title="Original Survey Results as Table 2",
          digits=2, intercept.bottom=FALSE, header = FALSE)
```


and the regression result from the dataset generated by ChatGPT: 
```{r reg2-pseudo, echo=FALSE, results='asis'}
# Model 1
reg21.pseudo <- lm(spend ~ welfare_word*rr_post,
                   data=pseudo.dat)
# summary(reg21)

# Model 2
reg22.pseudo <- lm(spend ~ welfare_word*rr_post*rr_scale, 
                   data=pseudo.dat)
# summary(reg22)

# outputting to nice txt table
# NOTE: R's ordering of coefficients in Model 2
#       differs slightly from that in the text
stargazer(reg21.pseudo, reg22.pseudo, 
          title="Pseudo Survey Results as Table 2",
          digits=2, intercept.bottom=FALSE, header = FALSE)
```

## Table 3: Regression Predicting Racial Resentment
```{r reg3, echo=FALSE, results='asis'}
# Model 1
reg31 <- lm(rr_scale ~ rr_post + I(rr_post*welfare_word),
           data=DAT)
# summary(reg31)

# Model 2
reg31.pseudo <- lm(rr_scale ~ rr_post + I(rr_post*welfare_word),
           data=pseudo.dat)
# summary(reg31.pseudo)

# outputting to nice txt table
stargazer(reg31, reg31.pseudo, 
          title="Pseudo Survey Results as Table 2",
          column.labels=c("original","pseudo"),
          digits=2, intercept.bottom=FALSE, header = FALSE)
```

# References

<div id="refs"></div>