---
title: "Wording Experiment Example"
author: "Ying Yan"
date: "2025-03-26"
output:
  pdf_document:
    citation_package: biblatex
    latex_engine: lualatex
biblio-style: apa
header-includes: \usepackage{hyperref}
bibliography: wordexperiment.bib
biblatexoptions: [backend=biber]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data and Code
The original survey data is taken from the supplementary material of @Albertson_Jessee_2023. The pseudo-
survey dataset is generated by ChatGPT by describing exactly the same setup and sample size as
the paper. The exact wording of this data generation prompt is shown in the Appendix. The data
generation code generated by ChatGPT and the code for this replication and comparison are available
at [Github](https://github.com/YingYan77/vignetteexample/tree/main).

```{r data-preparation, include=FALSE}
# loading data
library(rio)
library(mice)
library(stargazer)
library(bookdown)

DAT <- import("supplementary material-replicate codes/raw_data.dta")
pseudo.dat <- read.csv("data_recialresentment.csv")

# creating indicator for welfare/aid to poor 
# question wording
DAT$welfare_word <- NA
DAT$welfare_word[!is.na(DAT$Q32)] <- 1
DAT$welfare_word[!is.na(DAT$Q33)] <- 0

pseudo.dat$welfare_word <- NA
pseudo.dat$welfare_word[!is.na(pseudo.dat$Q32)] <- 1
pseudo.dat$welfare_word[!is.na(pseudo.dat$Q33)] <- 0

# creating welfare/assistance to the poor spending 
# response, combining across question wordings
DAT$spend <- ifelse(DAT$welfare_word==1, c(1, -1, 0)[DAT$Q32],
                    ifelse(DAT$welfare_word==0, c(1, -1, 0)[DAT$Q33], NA))

pseudo.dat$spend <- ifelse(pseudo.dat$welfare_word==1, c(1, -1, 0)[pseudo.dat$Q32],
                           ifelse(pseudo.dat$welfare_word==0, c(1, -1, 0)[pseudo.dat$Q33], NA))

# dropping the 1 observation with everything missing
DAT <- subset(DAT, !is.na(spend))

# dummy for asking RR battery post-experiment
DAT$rr_post <- 1 - DAT$race_first

# racial resentment scale
# first recoding each item 
DAT$rr1.raw <- (5 - DAT$Q22) / 4
DAT$rr2.raw <- (DAT$Q23 - 1) / 4
DAT$rr3.raw <- (DAT$Q24 - 1) / 4
DAT$rr4.raw <- (5 - DAT$Q25) / 4

# imputing missing RR items 
RRmice <- mice(cbind(DAT$rr1.raw, DAT$rr2.raw, DAT$rr3.raw, DAT$rr4.raw),
               seed=12345, method="pmm", maxit=100, m=10, print=FALSE)
RRimputed <- complete(RRmice)

DAT$rr1 <- RRimputed[,1]
DAT$rr2 <- RRimputed[,2]
DAT$rr3 <- RRimputed[,3]
DAT$rr4 <- RRimputed[,4]

pseudo.dat$rr1 <- (5 - pseudo.dat$Q22) / 4
pseudo.dat$rr2 <- (pseudo.dat$Q23 - 1) / 4
pseudo.dat$rr3 <- (pseudo.dat$Q24 - 1) / 4
pseudo.dat$rr4 <- (5 - pseudo.dat$Q25) / 4

# RR scale
DAT$rr_scale <- (DAT$rr1 + DAT$rr2 + DAT$rr3 + DAT$rr4) / 4
pseudo.dat$rr_scale <- (pseudo.dat$rr1 + pseudo.dat$rr2 + pseudo.dat$rr3 + pseudo.dat$rr4) / 4

```

# The Descriptive Demographics
A sample characteristics comparison between the original data and the dataset generated by ChatGPT. 
```{r descriptive, echo=FALSE, results='asis'}
# Function to compute proportions
compute_proportions1 <- function(DAT) {
  list(
    Female = mean(DAT$Q72 == 2, na.rm = TRUE),
    `College degree or higher` = mean(DAT$Q73 >= 5, na.rm = TRUE),
    White = mean(DAT$Q75 == 1, na.rm = TRUE),
    `Black or African American` = mean(DAT$Q75 == 2, na.rm = TRUE),
    `Asian or Asian American` = mean(DAT$Q75 == 4, na.rm = TRUE),
    `Liberal or Slightly Liberal` = mean(DAT$Q77 %in% 1:2, na.rm = TRUE),
    `Conservative or Slightly Conservative` = mean(DAT$Q77 %in% 4:5, na.rm = TRUE)
  )
}

compute_proportions2 <- function(DAT) {
  list(
    Female = mean(DAT$gender == 2, na.rm = TRUE),
    `College degree or higher` = mean(DAT$education >= 5, na.rm = TRUE),
    White = mean(DAT$ethnicity == 1, na.rm = TRUE),
    `Black or African American` = mean(DAT$ethnicity == 2, na.rm = TRUE),
    `Asian or Asian American` = mean(DAT$ethnicity == 4, na.rm = TRUE),
    `Liberal or Slightly Liberal` = mean(DAT$ideology %in% 1:2, na.rm = TRUE),
    `Conservative or Slightly Conservative` = mean(DAT$ideology %in% 4:5, na.rm = TRUE)
  )
}
# Compute proportions for both datasets
results1 <- compute_proportions1(DAT)
results2 <- compute_proportions2(pseudo.dat)

# Convert to a data frame
table_df <- data.frame(
  variables = names(results1),
  original = paste0(round(100 * unlist(results1), 0), "%"),
  pseudo = paste0(round(100 * unlist(results2), 0), "%")
)


# Generate LaTeX table in R Markdown
kableExtra::kable(table_df, format = "latex", booktabs = TRUE, align = "lcc",
      caption = "Comparison of Proportions Between Two Datasets") |>
  kableExtra::kable_styling(latex_options = c("hold_position"))
```

# The Regression Results
## Table 1: Effect of Question Wording on Spending Veiws (Ignoring Question Order)
The result from the original survey data is shown in Table 2.

```{r reg1, echo=FALSE, results='asis'}
# Model 1
reg11 <- lm(spend ~ welfare_word, data=DAT)
# summary(reg11)

# Model 2
reg12 <- lm(spend ~ welfare_word + rr_scale, data=DAT)
# summary(reg12)

# Model 3
reg13 <- lm(spend ~ welfare_word*rr_scale, data=DAT)
# summary(reg13)

stargazer(reg11, reg12, reg13,
          title="Orignal Survey Results as Table 1",
          digits=2, intercept.bottom=FALSE, header=FALSE)

```

The result of data generated by ChatGPT is show in Table 3.
```{r reg1-pseudo, echo=FALSE, results='asis'}
# Model 1
reg11.pseudo <- lm(spend ~ welfare_word, data=pseudo.dat)
# summary(reg11)

# Model 2
reg12.pseudo <- lm(spend ~ welfare_word + rr_scale, data=pseudo.dat)
# summary(reg12)

# Model 3
reg13.pseudo <- lm(spend ~ welfare_word*rr_scale, data=pseudo.dat)
# summary(reg13)

# outputting to formatted txt table
stargazer(reg11.pseudo, reg12.pseudo, reg13.pseudo, 
          title="Pseudo Survey Results as Table 1",
          digits=2, intercept.bottom=FALSE, header=FALSE)

```

## Table 2: Regression Predicting Spending Preferences on Welfare/Assistance to the Poor
The regression result from original dataset is shown in Table 4. 
```{r reg2, echo=FALSE, results='asis'}
# Model 1
reg21 <- lm(spend ~ welfare_word*rr_post,
           data=DAT)
# summary(reg21)

# Model 2
reg22 <- lm(spend ~ welfare_word*rr_post*rr_scale,
            data=DAT)
# summary(reg22)

# outputting to nice txt table
# NOTE: R's ordering of coefficients in Model 2
#       differs slightly from that in the text
stargazer(reg21, reg22,
          title="Original Survey Results as Table 2",
          digits=2, intercept.bottom=FALSE, header = FALSE)
```


and the regression result from the dataset generated by ChatGPT is shown in Table 5.  
```{r reg2-pseudo, echo=FALSE, results='asis'}
# Model 1
reg21.pseudo <- lm(spend ~ welfare_word*rr_post,
                   data=pseudo.dat)
# summary(reg21)

# Model 2
reg22.pseudo <- lm(spend ~ welfare_word*rr_post*rr_scale, 
                   data=pseudo.dat)
# summary(reg22)

# outputting to nice txt table
# NOTE: R's ordering of coefficients in Model 2
#       differs slightly from that in the text
stargazer(reg21.pseudo, reg22.pseudo, 
          title="Pseudo Survey Results as Table 2",
          digits=2, intercept.bottom=FALSE, header = FALSE)
```

## Table 3: Regression Predicting Racial Resentment
Table 6 shows the regression result from both original data and data generated from ChatGPT. 
```{r reg3, echo=FALSE, results='asis'}
# Model 1
reg31 <- lm(rr_scale ~ rr_post + I(rr_post*welfare_word),
           data=DAT)
# summary(reg31)

# Model 2
reg31.pseudo <- lm(rr_scale ~ rr_post + I(rr_post*welfare_word),
           data=pseudo.dat)
# summary(reg31.pseudo)

# outputting to nice txt table
stargazer(reg31, reg31.pseudo, 
          title="Pseudo Survey Results as Table 3",
          column.labels=c("original","pseudo"),
          digits=2, intercept.bottom=FALSE, header = FALSE)
```


# Appendix

## The prompt
I would like you to generate a synthetic survey dataset for my survey experiment. Please simulate realistic response patterns and generate a CSV dataset that I can download. Please name the dataset " data_recialresentment.csv”. Please then briefly explain your process for generating the dataset. Also include the sources underlying the sociographic distributions. Please also provide the python code that you use to generate the data. Finally, please formulate the research question underlying this experiment.

**Sample size**: 1590 simulated responses

**Distribution of the sample**:  Representative for the US in August 2021 separately according to: 

* Age (Min = 16; Max = 95);
* Gender (man = 1, woman = 2, non-binary = 3, self-describe = 4);
* highest level of education achieved (1 = did not graduate from high school; 2 = high school graduate, 3 = some colleague but no degree (yet), 4 = 2-year college degree, 5 = 4-year college degree, 6 = postgraduate degree);
* Annual income (1 = less than \$30,000; 2=\$30,000 to $39,999; 3 = $40,000 to $49,999; 4 = $50,000 t0 $59,999; 5 = $60,000 to $69,999; 6 = $70,000 to $79,999; 7 = $80,000 to $99,999; 8 = $100,000 to $119,999; 9 = $120,000 to $149,999; 10 = $150,000 to $199,999; 11 = $200,000 to $249,000; 12 = $250,000 or more; 13 = Prefer not to say);
* Ethnicities (1 = White, 2 = Black or African-American, 3 = Hispanic or Latino, 4 = Asian or Asian-American, 5 = Native American, 6 = Two or more races, 7 = Middle Eastern, 9 = Other), and 
* When Q75 == 6, then add Q7.6 as a multi-selective  ethnicities (1 = White, 2 = Black or African-American, 3 = Hispanic or Latino, 4 = Asian or Asian-American, 5 = Native American, 6 = Middle Eastern, 7 = Don’t Know) 
* Ideology(1 = Liberal, 2 = Slightly liberal, 3 = Moderate, 4 = Slightly conservative, 5 = Conservative)

The survey experiment is a question wording experiment conducted in in the US. There are four variants. Each respondent randomly sees one of the four variants depending on two independent indicators. The data set must contain two variables that indicate which variants the person has seen. The first variable indicates the type of the policy spending question (named Q32 and Q33) the person has to answer, and the second indicator affects the order between the policy spending question and a question battery of racial resentment. Please call the first indicator variable “welfare_word" and the second indicator variable “rr_post”. Please call the battery of racial resentment Q22, Q23, Q24, and Q25. Please estimate the answers for those questions depending on the sociodemographic characteristics of the respondents.

**Variant 0**: (welfare_word = 0 and rr_post = 0) The respondents received a policy spending question Q33 and a four-question battery of racial resentment before the policy spending question.

**Variant 1**: (welfare_word = 1 and rr_post = 0) The respondents received a policy spending question Q32 and a four-question battery of racial resentment before the policy spending question.

**Variant 2**: (welfare_word = 0 and rr_post = 1) The respondents received a policy spending question Q33, and a four-question battery of racial resentment after the policy spending question.

**Variant 3**: (welfare_word = 1 and rr_post = 1) The respondents received a policy spending question Q32, and a four-question battery of racial resentment after the policy spending question.

Q32: We are faced with many problems in this country, none of which can be solved easily or inexpensively. Please tell us whether you think we are spending too much, too little, or about the right amount on welfare.  

Answer option Q32: 1 “too much”; 2 “too little”; 3 “about the right amount”. 

Q33: We are faced with many problems in this country, none of which can be solved easily or inexpensively. Please tell us whether you think we are spending too much, too little, or about the right amount on assistance to the poor.  

Answer option Q33: 1 “too much”; 2 “too little”; 3 “about the right amount”.

Q22: Irish, Italians, Jewish and many other minorities overcame prejudice and worked their way up. Blacks should do the same without any special favors. 

Answer option 22: 1 “Agree strongly”; 2 “Agree somewhat”; 3 "Neither agree nor disagree”; 4 “Disagree somewhat”; and 5 “Disagree strongly”.

Q23: Generations of slavery and discrimination have created conditions that make it difficult for blacks to work their way out of the lower class.

Answer option 23: 1 “Agree strongly”; 2 “Agree somewhat”; 3 "Neither agree nor disagree”; 4 “Disagree somewhat”; and 5 “Disagree strongly”.

Q24: Over the past few years, blacks have gotten less than they deserve.  

Answer option 24: 1 “Agree strongly”; 2 “Agree somewhat”; 3 "Neither agree nor disagree”; 4 “Disagree somewhat”; and 5 “Disagree strongly”.

Q25: It’s really a matter of some people not trying hard enough; if blacks would only try harder they could be just as well off as whites.

Answer option 25: 1 “Agree strongly”; 2 “Agree somewhat”; 3 "Neither agree nor disagree”; 4 “Disagree somewhat”; and 5 “Disagree strongly”.
